# Google AI Dopamine, GLUE, TransmogrifAI, Machine Learning for Health Care, NLP Interpretability, Probabilistic Thinking,â€¦

![](https://cdn-images-1.medium.com/max/800/1*q3CcM8wFO0UQBEx6Y3zA8A.png)


*Great day awesome people and welcome to the 28th Issue of the NLP Newsletter! I am Elvis from Belize, Editor of* [*DAIR.ai*](https://medium.com/dair-ai)*, and a PhD researcher in AI and NLP. Here is this weekâ€™s notable NLP news: Understanding human intelligence and using it for AI progress; machine learning for healthcare recap; reinforcement learning reproducibility; state of the art machine translation; automated machine learning; earthquake aftershock locations prediction, and much more.*

ğŸ”â€Šâ€”â€Šmy top recommendations
ğŸŒŸâ€Šâ€”â€Šmy favorites

**On Peopleâ€¦**  
Read more on why schools are using AI to track students writing patterns based on what they type into their computersâ€Šâ€”â€Š[link](https://qz.com/1318758/schools-are-using-ai-to-track-what-students-write-on-their-computers/)

Irene Chen gives a recap on the important topics discussed at the Machine Learning for Health Care (MLHC) conferenceâ€Šâ€”â€Šfrom privacy to model robustness to clinical notes understandingâ€Šâ€”â€Š[link](http://irenechen.net/blog/2018/08/28/mlhc2018.html) ğŸ”

Nature releases a paper describing a deep learning approach to predict earthquake aftershock locations. The model is also useful to understand the underlying physics behind the phenomenaâ€Šâ€”â€Š[link](https://www.nature.com/articles/s41586-018-0438-y)

Yoshua Bengio discusses about the implications of disentangled representations for higher-level cognition. He also discusses how â€œnatural language could be used as an additional hint about the abstract representations and disentangled factors which humans have discovered to explain their worldâ€.â€Šâ€”â€Š[link](https://www.youtube.com/watch?v=Yr1mOzC93xs) ğŸ”

PyTorch is hosting its first developer conference where they aim to discuss research and production capabilities for their new release, PyTorch 1.0â€Šâ€”â€Š[link](https://pytorch.fbreg.com/)

DeepMind, in collaboration with Harvard professor Wouter Kool, releases new paper investigating how human-decision makers deploy mental effort and how these insights can give way to opportunities and progress in recent artificial intelligence researchâ€Šâ€”â€Š[link](https://www.nature.com/articles/s41562-018-0401-9?error=cookies_not_supported&code=a786401e-89d6-40c9-9332-50c9ed0b9e44) ğŸŒŸ

**On Education and Researchâ€¦**  
Google AI releases Dopamine, a Tensor-based framework that provides flexibility, stability, and reproducibility for new and experienced reinforcement learning researchersâ€Šâ€”â€Š[link](https://ai.googleblog.com/2018/08/introducing-new-framework-for-flexible.html)

In a new episode of the NLP Highlight show, researchers discuss the importance of establishing a benchmark framework, known as GLUE, for natural language understandingâ€Šâ€”â€Š[link](https://soundcloud.com/nlp-highlights/67-glue-a-multi-task-benchmark-and-analysis-platform-with-sam-bowman) ğŸŒŸ

Authors of a new research claims how information obtained from paraphrases can be used to improve multilingual machine translationâ€Šâ€”â€Š[link](https://arxiv.org/abs/1808.08438)

A new paper discusses the capability of text classifiers to recover demographic information from textual data with reasonable accuracyâ€Šâ€”â€Š[link](https://arxiv.org/abs/1808.06640)

A recent work compares the robustness of humans and current convolutional deep neural networks (DNNs) on object recognition under twelve different type of image degradations. They mainly test for generalization capabilities and how weaknesses observed in DNNs can be systematically addressed using a lifelong machine learning approachâ€Šâ€”â€Š[link](https://arxiv.org/abs/1808.08750)

Find out how text generation can be done using an alternative method, based on a hidden semi-markov model (HSMM) decoder, achieving similar performance to the standard encode-decoder models. The proposed model provides a method which allows for more interpretability and controlâ€Šâ€”â€Šsomething the authors claim is important in a text generation taskâ€Šâ€”â€Š[link](https://arxiv.org/abs/1808.10122)

Facebookâ€™s research team releases a field guide to applying machine learning. It provides real-world best practices and practical approaches on how to apply machine-learning capabilities to real-world problems (video series)â€Šâ€”â€Š[link](https://research.fb.com/the-facebook-field-guide-to-machine-learning-video-series/)

**On Code and Dataâ€¦**  
DeepMind researcher, Shakir Mohamed, releases an impressive set of slides where he introduces foundations, tricks, and algorithms needed for probabilistic thinkingâ€Šâ€”â€Š[link](https://www.shakirm.com/slides/MLSS2018-Madrid-ProbThinking.pdf) ğŸ”

A comprehensive list of tutorials on how to build machine learning algorithms from scratchâ€Šâ€”â€Š[link](https://github.com/eriklindernoren/ML-From-Scratch)

Bloomberg researcher, Yi Yang, releases code and paper for his new work on modeling convolutional filters with RNNs, which he claims naturally capture long-term dependencies and compositionality in languageâ€Šâ€”â€Š[link to paper](https://arxiv.org/abs/1808.09315) | [link to code](https://github.com/bloomberg/cnn-rnf)

PyImageSearch just published a new tutorial on how to perform semantic segmentation using OpenCV and deep learning. The method works for both images and videosâ€Šâ€”â€Š[link](https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/)

**On Industryâ€¦**  
Salesforceâ€™s Einstein AI team releases TransmogrifAI, an AutoML library that focuses on accelerating machine learning developer productivity through automated machine learning for structured dataâ€Šâ€”â€Š[link](https://transmogrif.ai/)

Facebook researchers come up with a state of the art method for machine translation that only relies on monolingual corpora which can be useful to deal with low-resource languagesâ€Šâ€”â€Š[link](https://www.forbes.com/sites/samshead/2018/08/31/facebook-develops-new-ai-technique-for-language-translation/#50f8e352f71b) | [paper](https://arxiv.org/abs/1804.07755)

Here is a nice list of Machine Learning rules and best practices for deploying real-world ML-based apps provided by Googleâ€™s ML teamâ€Šâ€”â€Š[link](https://developers.google.com/machine-learning/guides/rules-of-ml/) ğŸ”

**Quote of the weekâ€¦**  

![](https://cdn-images-1.medium.com/max/800/0*pehYwp_3IIKugeYa.png)


[Source](https://twitter.com/ethanwhite/status/1035505001303625728)

**Worthy Mentionsâ€¦**  
dair.ai releases new post on the state of deep learning based natural language processing techniquesâ€Šâ€”â€Š[link](https://medium.com/dair-ai/deep-learning-for-nlp-an-overview-of-recent-trends-d0d8f40a776d) ğŸ”

MIT Review releases new article explaining all the important details on the new sensational machine learning method used to transfer one personâ€™s motion to another (i.e., Everybody Dance Now)â€Šâ€”â€Š[link](https://www.technologyreview.com/s/611941/easy-to-make-videos-can-show-you-dancing-like-the-stars/)

Check out a collection of inspirational AI-powered Javascript apps in this cool website. Submissions use tools such as Tensorflow.js, Magenta.js, p5.js, and othersâ€Šâ€”â€Š[link](https://aijs.rocks/)

Skynet this week #7: OpenAIâ€™s big loss, DeekFake dancing, AI drawing, and more!â€Šâ€”â€Š[link](https://www.skynettoday.com/digests/the-seventh)

The NLP Newsletter (Issue 27): Deep INFOMAX, Image to Image Translation, FEVER, Perception Engines, QuAC, Best 150 ML Tutorialsâ€Šâ€”â€Š[link](https://medium.com/dair-ai/deep-infomax-image-to-image-translation-fever-perception-engines-quac-best-150-ml-tutorials-71904cbcffb7)

Sebastian Ruderâ€™s NLP Newsletter (Issue #31)â€Šâ€”â€Š[link](http://newsletter.ruder.io/issues/fake-video-state-of-ml-code-notebooks-and-software-advice-for-mscing-and-phding-ada-lovelace-150-best-resources-130205)

Alignment Newsletter #22â€Šâ€”â€ŠResearch agenda for AI governanceâ€Šâ€”â€Š[link](https://mailchi.mp/469203093ca3/alignment-newsletter-22)

*If you spot any errors or inaccuracies in this newsletter please comment below. I would appreciate if you can help me to improve the newsletter by commenting your suggestions below. Otherwise, just help me by sharing the NLP newsletter. If you have any further questions DM me at* [*@omarsar0*](https://twitter.com/omarsar0)*!*

